{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have TensorFlow version 1.3.0\n",
      "Train size: 35\n",
      "Test size: 15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# # import glob for iterating files in folder and use dataframe for structuring\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "body=[]\n",
    "list_of_files = glob.glob('./spam_data/0*.txt')\n",
    "\n",
    "for fileName in list_of_files:\n",
    "    \n",
    "    file = open(fileName, encoding = \"ISO-8859-1\")\n",
    "    body.append(file.read())\n",
    "    \n",
    "    file.close()\n",
    "\n",
    "body_file = pd.DataFrame(data = body,columns = ['post'])\n",
    "\n",
    "\n",
    "label_file = pd.read_csv('./spam_data/labels.txt',header = None,delimiter=\" \",names=[\"label\",'Name'])\n",
    "\n",
    "\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "get_ipython().magic('matplotlib inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.contrib.keras.python import keras\n",
    "from tensorflow.contrib.keras.python.keras.models import Sequential\n",
    "from tensorflow.contrib.keras.python.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.contrib.keras.python.keras.preprocessing import text, sequence\n",
    "from tensorflow.contrib.keras.python.keras import utils\n",
    "\n",
    "# This code was tested with TensorFlow v1.3\n",
    "print(\"You have TensorFlow version\", tf.__version__)\n",
    "\n",
    "\n",
    "train_size = int(len(body_file) * .7)\n",
    "print (\"Train size: %d\" % train_size)\n",
    "print (\"Test size: %d\" % (len(body_file) - train_size))\n",
    "\n",
    "np.random.seed()\n",
    "train_posts = body_file['post'][:train_size]\n",
    "train_tags = label_file['label'][:train_size]\n",
    "\n",
    "test_posts = body_file['post'][train_size:]\n",
    "test_tags = label_file['label'][train_size:]\n",
    "\n",
    "len(train_posts), len(train_tags)\n",
    "\n",
    "\n",
    "\n",
    "len(test_posts), len(test_tags)\n",
    "\n",
    "\n",
    "\n",
    "max_words = 100\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg =tokenize.fit_on_texts('hi')\n",
    "gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenize.fit_on_texts(train_posts) # only fit on train\n",
    "\n",
    "\n",
    "text = \"the\"\n",
    "\n",
    "tokenize.texts_to_matrix([text])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_train = tokenize.texts_to_matrix(train_posts)\n",
    "x_test = tokenize.texts_to_matrix(test_posts)\n",
    "\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)\n",
    "\n",
    "\n",
    "\n",
    "from scipy.spatial import distance\n",
    "def eucledean(a,b):\n",
    "        return distance.euclidean(a,b)\n",
    "    \n",
    "def euclideanDistance(instance1, instance2, length):\n",
    "\tdistance = 0\n",
    "\tfor x in range(length):\n",
    "\t\tdistance += pow((instance1[x] - instance2[x]), 2)\n",
    "\treturn math.sqrt(distance)\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "#Custom Classifier\n",
    "class myCustomClassifier():\n",
    "    def __init__(self,n_number = 3):\n",
    "        self.n_number = n_number\n",
    "    \n",
    "    def fit(self,x_train,y_train):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def closest(self,row):\n",
    "        \n",
    "        tempDist = []\n",
    "        tempFull = []\n",
    "       \n",
    "        counter = 0\n",
    "        \n",
    "        for i in range(1,len(x_train)):\n",
    "            \n",
    "            dist = eucledean(row,self.x_train[i])\n",
    "            tempDist.append((dist,self.y_train[i]))\n",
    "           \n",
    "        \n",
    "        tempFull = [i[1] for i in sorted(tempDist)[:self.n_number]]\n",
    "        \n",
    "        voteResult = Counter(tempFull).most_common(1)[0][0]\n",
    "       \n",
    "        # Takes votes of k - number and returns label which has most votes          \n",
    "        return voteResult\n",
    "    \n",
    "    \n",
    "        \n",
    "    def predict(self,x_test):\n",
    "        \n",
    "        predictions = []\n",
    "        for row in x_test:\n",
    "            label = self.closest(row)\n",
    "            predictions.append(label)\n",
    "        return predictions\n",
    "    \n",
    "#Implementing custom classifier\n",
    "knn = myCustomClassifier(3)\n",
    "knn.fit(x_train, y_train) \n",
    "\n",
    "\n",
    "Final_predictions = knn.predict(x_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :- \",accuracy_score(y_test,Final_predictions))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
